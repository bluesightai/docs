{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f83fa75-861f-4ce3-a591-a7a370e17e3b",
   "metadata": {},
   "source": [
    "This guide shows how to train and infer [Clay Foundation Model](https://clay-foundation.github.io/model/index.html) for segmentation task ([Chesapeake Land Cover\n",
    "](https://lila.science/datasets/chesapeakelandcover)) using our API.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bluesightai/docs/blob/main/guides/train-a-land-segmentation.ipynb\">\n",
    "  <img noZoom src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4438c8b3-2d56-4eaa-a25f-add185aee802",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.bluesight.ai\"\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "GSD = 1.0\n",
    "CHIP_SIZE = 224\n",
    "COLLECTION = \"naip\"\n",
    "BANDS = [\"red\", \"green\", \"blue\", \"nir\"]\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "N_TRAIN_SAMPLES = 2\n",
    "N_TEST_SAMPLES = 100\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d4ffc1f",
   "metadata": {},
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdf473-1152-4ce1-8fec-d44ee5ba78a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading data\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fe48c00",
   "metadata": {},
   "source": [
    "!aws s3 cp s3://us-west-2.opendata.source.coop/agentmorris/lila-wildlife/lcmcvpr2019/cvpr_chesapeake_landcover/ny_1m_2013_extended-debuffered-train_tiles/ data/train/ --recursive --no-sign-request --region us-west-2 --exclude \"*\" --include \"*_lc.tif\" --include \"*_naip-new.tif\"\n",
    "!aws s3 cp s3://us-west-2.opendata.source.coop/agentmorris/lila-wildlife/lcmcvpr2019/cvpr_chesapeake_landcover/ny_1m_2013_extended-debuffered-val_tiles/ data/val/ --recursive --no-sign-request --region us-west-2 --exclude \"*\" --include \"*_lc.tif\" --include \"*_naip-new.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da9754",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing data\n",
    "\n",
    "https://github.com/Clay-foundation/model/blob/main/finetune/segment/preprocess_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca42188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a92363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                       | 0/100 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_431912/265639411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mval_label_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*_lc.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mprocess_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train/chips\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHIP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprocess_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train/labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHIP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprocess_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"val/chips\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHIP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_431912/265639411.py\u001b[0m in \u001b[0;36mprocess_files\u001b[0;34m(file_paths, output_dir, chip_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mread_and_chip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchip_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_431912/265639411.py\u001b[0m in \u001b[0;36mread_and_chip\u001b[0;34m(file_path, chip_size, output_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;34mf\"{Path(file_path).stem}_chip_{chip_number}.npy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 )\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mchip_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/share/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    523\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/anaconda3/lib/python3.9/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(DATA_DIR)\n",
    "OUTPUT_DIR = DATA_DIR / \"output\"\n",
    "\n",
    "def read_and_chip(file_path, chip_size, output_dir):\n",
    "    \"\"\"\n",
    "    Reads a GeoTIFF file, creates chips of specified size, and saves them as\n",
    "    numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        file_path (str or Path): Path to the GeoTIFF file.\n",
    "        chip_size (int): Size of the square chips.\n",
    "        output_dir (str or Path): Directory to save the chips.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with rio.open(file_path) as src:\n",
    "        data = src.read()\n",
    "\n",
    "        n_chips_x = src.width // chip_size\n",
    "        n_chips_y = src.height // chip_size\n",
    "\n",
    "        chip_number = 0\n",
    "        for i in range(n_chips_x):\n",
    "            for j in range(n_chips_y):\n",
    "                x1, y1 = i * chip_size, j * chip_size\n",
    "                x2, y2 = x1 + chip_size, y1 + chip_size\n",
    "\n",
    "                chip = data[:, y1:y2, x1:x2]\n",
    "                chip_path = os.path.join(\n",
    "                    output_dir,\n",
    "                    f\"{Path(file_path).stem}_chip_{chip_number}.npy\",\n",
    "                )\n",
    "                np.save(chip_path, chip)\n",
    "                chip_number += 1\n",
    "\n",
    "\n",
    "def process_files(file_paths, output_dir, chip_size):\n",
    "    \"\"\"\n",
    "    Processes a list of files, creating chips and saving them.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list of Path): List of paths to the GeoTIFF files.\n",
    "        output_dir (str or Path): Directory to save the chips.\n",
    "        chip_size (int): Size of the square chips.\n",
    "    \"\"\"\n",
    "    for file_path in tqdm(file_paths):\n",
    "        read_and_chip(file_path, chip_size, output_dir)\n",
    "        \n",
    "\n",
    "train_image_paths = list((DATA_DIR / \"train\").glob(\"*_naip-new.tif\"))\n",
    "train_label_paths = list((DATA_DIR / \"train\").glob(\"*_lc.tif\"))\n",
    "val_image_paths = list((DATA_DIR / \"val\").glob(\"*_naip-new.tif\"))\n",
    "val_label_paths = list((DATA_DIR / \"val\").glob(\"*_lc.tif\"))\n",
    "\n",
    "process_files(train_image_paths, OUTPUT_DIR / \"train/chips\", CHIP_SIZE)\n",
    "process_files(train_label_paths, OUTPUT_DIR / \"train/labels\", CHIP_SIZE)\n",
    "process_files(val_image_paths, OUTPUT_DIR / \"val/chips\", CHIP_SIZE)\n",
    "process_files(val_label_paths, OUTPUT_DIR / \"val/labels\", CHIP_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6988f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chip_names = [chip_path.name for chip_path in list((OUTPUT_DIR / \"train/chips\").glob(\"*.npy\"))]\n",
    "train_label_names = [re.sub(\"_naip-new_\", \"_lc_\", chip) for chip in train_chip_names]\n",
    "\n",
    "val_chip_names = [chip_path.name for chip_path in list((OUTPUT_DIR / \"val/chips\").glob(\"*.npy\"))]\n",
    "val_label_names = [re.sub(\"_naip-new_\", \"_lc_\", chip) for chip in val_chip_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff8de272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 320.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 206.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 180.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 237.22it/s]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 15: 6}\n",
    "\n",
    "X_train = [{\n",
    "    \"gsd\": GSD,\n",
    "    \"bands\": BANDS,\n",
    "    \"pixels\": np.load(OUTPUT_DIR / \"train/chips\" / chip_name).tolist(),\n",
    "    \"platform\": COLLECTION\n",
    "} for chip_name in tqdm(train_chip_names[:N_TRAIN_SAMPLES])]\n",
    "y_train = [{\"label\": np.vectorize(label_mapping.get)(np.load(OUTPUT_DIR / \"train/labels\" / chip_name).squeeze()).tolist()} for chip_name in tqdm(train_label_names[:N_TRAIN_SAMPLES])]\n",
    "\n",
    "X_test = [{\n",
    "    \"gsd\": GSD,\n",
    "    \"bands\": BANDS,\n",
    "    \"pixels\": np.load(OUTPUT_DIR / \"val/chips\" / chip_name).tolist(),\n",
    "    \"platform\": COLLECTION\n",
    "} for chip_name in tqdm(val_chip_names[:N_TEST_SAMPLES])]\n",
    "y_test = [{\"label\": np.vectorize(label_mapping.get)(np.load(OUTPUT_DIR / \"val/labels\" / chip_name).squeeze()).tolist()} for chip_name in tqdm(val_label_names[:N_TEST_SAMPLES])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb33378d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_431912/3107972419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrandom_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_image_mask_pair(image, mask, title=\"Image and Mask Pair\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(mask, cmap='viridis')\n",
    "    ax2.set_title(\"Segmentation Mask\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "random_indices = np.random.choice(len(X_train), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image = np.array(X_train[idx]['pixels']).transpose(1, 2, 0)\n",
    "    mask = np.array(y_train[idx]['labels'])\n",
    "    \n",
    "    if image.shape[2] > 3:\n",
    "        image = image[:, :, :3]\n",
    "    \n",
    "    visualize_image_mask_pair(image, mask, f\"Random Sample {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281a921-e6fd-4f2d-8604-52025e92714c",
   "metadata": {},
   "source": [
    "## Training model\n",
    "\n",
    "Now we need to load data to the format which is accepted by our API. Essentially, it is raw pixels data from all bands with some metadata.\n",
    "\n",
    "You can check detailed endpoint specification [in the docs](https://docs.bluesight.ai/api-reference/train/train-segmentation-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a0868a-d95c-4f1e-91f9-32aac5bc06c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model id: '123'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = API_URL + \"/train/segmentation\"\n",
    "payload = {\"images\": X_train, \"labels\": y_train}\n",
    "response = requests.request(\"POST\", url, json=payload, headers=HEADERS)\n",
    "if response.status_code != 200:\n",
    "    print(f\"{response.status_code}: {response.json()}\")\n",
    "else:\n",
    "    data = response.json()\n",
    "    model_id, train_details = data[\"model_id\"], data[\"train_details\"]\n",
    "    print(f\"Model id: '{model_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ad1d8-bdf6-466c-bef9-d8f952c43c3a",
   "metadata": {},
   "source": [
    "## Run inference\n",
    "\n",
    "For inference we need only images.\n",
    "\n",
    "You can check detailed endpoint specification [in the docs](https://docs.bluesight.ai/api-reference/inference/infer-segmentation-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf46f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8058984e-5ac5-4d4c-977c-cde3692f8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = API_URL + \"/inference/classification\"\n",
    "payload = {\"images\": X_test, \"model_id\": model_id}\n",
    "response = requests.request(\"POST\", url, json=payload, headers=HEADERS)\n",
    "if response.status_code != 200:\n",
    "    print(f\"{response.status_code}: {response.json()}\")\n",
    "else:\n",
    "    y_pred = response.json()[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b96aa6-1de1-41f8-8c8f-825f00d77e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 778 out of 800 correctly\n",
      "Accuracy: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       600\n",
      "           1       0.94      0.95      0.95       200\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.96      0.96      0.96       800\n",
      "weighted avg       0.97      0.97      0.97       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "match = np.sum(np.array(y_test) == np.array(y_pred))\n",
    "print(f\"Matched {match} out of {len(y_test)} correctly\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
